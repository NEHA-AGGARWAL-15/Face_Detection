{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91c77a7-6962-4cad-830d-daaaaaaec608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shan\\Documents\\projects\\CrimiDatabase\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shan\\Documents\\projects\\CrimiDatabase\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Shan\\Documents\\projects\\CrimiDatabase\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shan\\Documents\\projects\\CrimiDatabase\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shan\\Documents\\projects\\CrimiDatabase\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shan\\Documents\\projects\\CrimiDatabase\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 67.2737 - accuracy: 0.2500 - val_loss: -5047.0850 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 446ms/step - loss: -14675.1367 - accuracy: 0.5000 - val_loss: -9831.1934 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 297ms/step - loss: -32494.4629 - accuracy: 0.5000 - val_loss: -15020.3711 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 270ms/step - loss: -36428.3281 - accuracy: 0.5000 - val_loss: -20236.2773 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 274ms/step - loss: -55911.5898 - accuracy: 0.5000 - val_loss: -25684.6387 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 265ms/step - loss: -77433.3125 - accuracy: 0.5000 - val_loss: -31424.8047 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 289ms/step - loss: -83768.2969 - accuracy: 0.5000 - val_loss: -37406.3125 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 255ms/step - loss: -108781.7656 - accuracy: 0.5000 - val_loss: -44030.4023 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 277ms/step - loss: -130329.9844 - accuracy: 0.5000 - val_loss: -50980.2656 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 268ms/step - loss: -132663.2500 - accuracy: 0.5000 - val_loss: -58237.5078 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shan\\Documents\\projects\\CrimiDatabase\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import os\n",
    "\n",
    "# Function to preprocess image into grayscale and trainable format\n",
    "def preprocess_image_gray(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = img.convert('L')  # Convert image to grayscale\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Sample paths to sets of images with respective IDs\n",
    "images_set1 = ['C:/Users/Shan/Desktop/img_processing/images.jpg', 'C:/Users/Shan/Desktop/img_processing/images_1.jpg', 'C:/Users/Shan/Desktop/img_processing/images_2.jpg']\n",
    "images_set2 = ['C:/Users/Shan/Desktop/img_processing/images4.jpg', 'C:/Users/Shan/Desktop/img_processing/images5.jpg', 'C:/Users/Shan/Desktop/img_processing/images6.jpg']\n",
    "ids = [1, 2]  # IDs corresponding to each set of images\n",
    "\n",
    "# Combine image paths and IDs for training data\n",
    "all_image_paths = images_set1 + images_set2\n",
    "all_labels = np.array(ids * len(images_set1))  # Repeated IDs for corresponding images\n",
    "\n",
    "# Convert all images to grayscale and trainable format\n",
    "all_images_gray = np.concatenate([preprocess_image_gray(img_path) for img_path in all_image_paths])\n",
    "\n",
    "# Define a new model architecture for grayscale images\n",
    "model_gray = Sequential()\n",
    "model_gray.add(Flatten(input_shape=(224, 224, 1)))  # Adjust input shape for grayscale images\n",
    "model_gray.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_gray.add(Dropout(0.5))\n",
    "model_gray.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_gray.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on grayscale images\n",
    "model_gray.fit(all_images_gray, all_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the grayscale model\n",
    "model_gray.save('grayscale_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b748fe3-cbbf-45b1-a076-fe0af1d59354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000129A13EFE20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000129A13EFE20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 205ms/step\n",
      "Predicted ID for the new image: 1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to preprocess image into grayscale and trainable format\n",
    "def preprocess_image_gray(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = img.convert('L')  # Convert image to grayscale\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Function to predict ID for a new image using the loaded model\n",
    "def predict_id_with_gray_model(model_path, new_image_path):\n",
    "    # Load the grayscale model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Preprocess the new image\n",
    "    new_image = preprocess_image_gray(new_image_path)\n",
    "    \n",
    "    # Predict the ID of the new image using the loaded model\n",
    "    predicted_prob = model.predict(new_image)[0]\n",
    "    \n",
    "    # Convert predicted probability to ID (example: round the probability)\n",
    "    threshold = 0.5  # Adjust the threshold as needed\n",
    "    predicted_id = 1 if predicted_prob > threshold else 2  # Replace with your IDs\n",
    "    \n",
    "    return predicted_id\n",
    "\n",
    "# Path to the new image for prediction\n",
    "new_image_path = 'C:/Users/Shan/Desktop/img_processing/images5.jpg'  # Replace with new image path\n",
    "model_path = 'grayscale_model.h5'  # Replace with your model's path\n",
    "\n",
    "# Predict the ID for the new image using the grayscale model\n",
    "predicted_id = predict_id_with_gray_model(model_path, new_image_path)\n",
    "\n",
    "print(f\"Predicted ID for the new image: {predicted_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6afcb5-b2d9-4318-b8d4-5ed58fae1e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 150.8792 - accuracy: 0.2500 - val_loss: 4.5805 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 4.5805 - accuracy: 1.0000 - val_loss: 4.2239 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 4.2239 - accuracy: 1.0000 - val_loss: 3.9793 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 3.9793 - accuracy: 1.0000 - val_loss: 3.8249 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 3.8249 - accuracy: 1.0000 - val_loss: 3.7442 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 3.7442 - accuracy: 1.0000 - val_loss: 3.7229 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 3.7229 - accuracy: 1.0000 - val_loss: 3.7482 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 3.7482 - accuracy: 1.0000 - val_loss: 3.8081 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 3.8081 - accuracy: 1.0000 - val_loss: 3.8922 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 3.8922 - accuracy: 1.0000 - val_loss: 3.9909 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Function to preprocess image into grayscale and trainable format\n",
    "def preprocess_image_gray(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = img.convert('L')  # Convert image to grayscale\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Sample paths to sets of images with respective IDs\n",
    "images_set1 = ['C:/Users/Shan/Desktop/img_processing/images.jpg', 'C:/Users/Shan/Desktop/img_processing/images_1.jpg', 'C:/Users/Shan/Desktop/img_processing/images_2.jpg']\n",
    "images_set2 = ['C:/Users/Shan/Desktop/img_processing/images4.jpg', 'C:/Users/Shan/Desktop/img_processing/images5.jpg', 'C:/Users/Shan/Desktop/img_processing/images6.jpg']\n",
    "ids = [0, 1]  # IDs corresponding to each set of images\n",
    "\n",
    "# Combine image paths and IDs for training data\n",
    "all_image_paths = images_set1 + images_set2\n",
    "all_labels = np.array([ids[i // len(images_set1)] for i in range(len(images_set1) + len(images_set2)) for _ in range(len(images_set1))])\n",
    "\n",
    "# Convert all images to grayscale and trainable format\n",
    "all_images_gray = np.concatenate([preprocess_image_gray(img_path) for img_path in all_image_paths])\n",
    "\n",
    "# Define a new model architecture for grayscale images\n",
    "model_gray = Sequential()\n",
    "model_gray.add(Flatten(input_shape=(224, 224, 1)))  # Adjust input shape for grayscale images\n",
    "model_gray.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model_gray.add(Dropout(0.5))\n",
    "model_gray.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_gray.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on grayscale images\n",
    "model_gray.fit(all_images_gray, all_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the grayscale model\n",
    "model_gray.save('grayscale_model_updated.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b08f3bfa-287a-433f-bc76-c3c861f4865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 117ms/step\n",
      "Predicted ID for the new image: 0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to preprocess image into grayscale and trainable format\n",
    "def preprocess_image_gray(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = img.convert('L')  # Convert image to grayscale\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Function to predict ID for a new image using the loaded model\n",
    "def predict_id_with_gray_model(model_path, new_image_path):\n",
    "    # Load the grayscale model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Preprocess the new image\n",
    "    new_image = preprocess_image_gray(new_image_path)\n",
    "    \n",
    "    # Predict the ID of the new image using the loaded model\n",
    "    predicted_id = np.argmax(model.predict(new_image))\n",
    "    \n",
    "    return predicted_id\n",
    "\n",
    "# Path to the new image for prediction\n",
    "new_image_path = 'C:/Users/Shan/Desktop/img_processing/images5.jpg'  # Replace with new image path\n",
    "model_path = 'grayscale_model_updated.h5'  # Replace with your model's path\n",
    "\n",
    "# Predict the ID for the new image using the grayscale model\n",
    "predicted_id = predict_id_with_gray_model(model_path, new_image_path)\n",
    "\n",
    "print(f\"Predicted ID for the new image: {predicted_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33d0e3d9-c928-4bef-92c3-cbfeae4cf0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model = load_model(model_path)\n",
    "    \n",
    "    # Preprocess the new image\n",
    "new_image = preprocess_image_gray(new_image_path)\n",
    "model.predict(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec412b-e7a7-4f78-81d0-467cd98f7a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15f10f6-ea91-4992-8ac3-84490afbd3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c87f0b2-3ce2-4c6d-b824-ba6090bbefe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shan\\Documents\\projects\\CrimiDatabase\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shan\\Documents\\projects\\CrimiDatabase\\venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Shan\\Documents\\projects\\CrimiDatabase\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shan\\Documents\\projects\\CrimiDatabase\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 9.1495\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 9.1495\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 9.1495\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 9.1495\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 9.1495\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 9.1495\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 9.1495\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 9.1495\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 9.1495\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 738ms/step - loss: 9.1495\n",
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Function to preprocess images\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Function to create Siamese network\n",
    "def create_siamese_network(input_shape):\n",
    "    input_image = Input(shape=input_shape)\n",
    "    flat = Flatten()(input_image)\n",
    "    dense1 = Dense(256, activation='relu')(flat)\n",
    "    dropout1 = Dropout(0.5)(dense1)\n",
    "    dense2 = Dense(128, activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.5)(dense2)\n",
    "    output = Dense(64)(dropout2)\n",
    "    \n",
    "    model = Model(inputs=input_image, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Function to create the Siamese model\n",
    "def create_siamese_model(siamese_network, input_shape):\n",
    "    input_image1 = Input(shape=input_shape)\n",
    "    input_image2 = Input(shape=input_shape)\n",
    "    \n",
    "    output1 = siamese_network(input_image1)\n",
    "    output2 = siamese_network(input_image2)\n",
    "    \n",
    "    # Custom distance function to measure similarity\n",
    "    def euclidean_distance(vects):\n",
    "        x, y = vects\n",
    "        sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "        return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "    distance = Lambda(euclidean_distance)([output1, output2])\n",
    "    \n",
    "    siamese_model = Model(inputs=[input_image1, input_image2], outputs=distance)\n",
    "    return siamese_model\n",
    "\n",
    "# Prepare data\n",
    "images_set1 = ['C:/Users/Shan/Desktop/img_processing/images.jpg', 'C:/Users/Shan/Desktop/img_processing/images_1.jpg', 'C:/Users/Shan/Desktop/img_processing/images_2.jpg']\n",
    "images_set2 = ['C:/Users/Shan/Desktop/img_processing/images4.jpg', 'C:/Users/Shan/Desktop/img_processing/images5.jpg', 'C:/Users/Shan/Desktop/img_processing/images6.jpg']\n",
    "names = ['Set 1', 'Set 2']\n",
    "\n",
    "image_paths = images_set1 + images_set2\n",
    "\n",
    "pairs = []\n",
    "labels = []\n",
    "\n",
    "for i, img_path1 in enumerate(image_paths):\n",
    "    for j, img_path2 in enumerate(image_paths):\n",
    "        if i != j:\n",
    "            pairs.append((img_path1, img_path2))\n",
    "            labels.append(1 if names[i // len(images_set1)] == names[j // len(images_set1)] else 0)\n",
    "\n",
    "# Convert pairs and labels to numpy arrays\n",
    "pairs = np.array(pairs)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split pairs into left and right images\n",
    "left_images = pairs[:, 0]\n",
    "right_images = pairs[:, 1]\n",
    "\n",
    "# Load and preprocess left and right images\n",
    "left_images_processed = np.array([load_and_preprocess_image(img_path) for img_path in left_images])\n",
    "right_images_processed = np.array([load_and_preprocess_image(img_path) for img_path in right_images])\n",
    "\n",
    "# Reshape left and right images for Siamese model input\n",
    "left_images_processed = left_images_processed.reshape(-1, 224, 224, 3)\n",
    "right_images_processed = right_images_processed.reshape(-1, 224, 224, 3)\n",
    "\n",
    "# Create Siamese network and model\n",
    "input_shape = (224, 224, 3)  # Change dimensions based on your images\n",
    "siamese_network = create_siamese_network(input_shape)\n",
    "siamese_model = create_siamese_model(siamese_network, input_shape)\n",
    "\n",
    "siamese_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001))\n",
    "\n",
    "# Train the Siamese model\n",
    "siamese_model.fit([left_images_processed, right_images_processed], labels, batch_size=32, epochs=10)\n",
    "\n",
    "# siamese_model.save(\"model/\")\n",
    "# import joblib\n",
    "\n",
    "# Assuming 'siamese_model' is your trained model\n",
    "# model_save_path = 'siamese_model.pkl'\n",
    "\n",
    "# Save the model using joblib\n",
    "# joblib.dump(siamese_model, model_save_path)\n",
    "\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "# Assuming 'siamese_model' is your trained model\n",
    "model_save_path = 'model'\n",
    "\n",
    "# Save the model using TensorFlow's save_model function\n",
    "save_model(siamese_model, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e558b2-07d0-47a2-8a5b-c20975d83d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_name_for_image(new_image_path, image_paths, names, siamese_model):\n",
    "    # Load and preprocess the new image\n",
    "    new_image = load_and_preprocess_image(new_image_path)\n",
    "    new_image_processed = new_image.reshape(1, 224, 224, 3)\n",
    "    \n",
    "    max_similarity = 0\n",
    "    predicted_name = \"No match found\"\n",
    "    \n",
    "    # Compare the new image with each image in the training set\n",
    "    for i in range(len(image_paths)):\n",
    "        similarity_score = siamese_model.predict([new_image_processed, \n",
    "                                                  load_and_preprocess_image(image_paths[i]).reshape(1, 224, 224, 3)])\n",
    "        if similarity_score > max_similarity:\n",
    "            max_similarity = similarity_score\n",
    "            predicted_name = names[i // len(images_set1)]\n",
    "    \n",
    "    return predicted_name\n",
    "\n",
    "new_image_path = 'C:/Users/Shan/Desktop/img_processing/images5.jpg'\n",
    "# predicted_name = predict_name_for_image(new_image_path, image_paths, names, siamese_model)\n",
    "# print(f\"Predicted Name for the new image: {predicted_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e45dcf-0900-42d2-9193-9171521e331e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shan\\Documents\\projects\\CrimiDatabase\\venv\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shan\\Documents\\projects\\CrimiDatabase\\venv\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model using TensorFlow's load_model function\n",
    "loaded_siamese_model = load_model(model_save_path)\n",
    "new_image_path = 'C:/Users/Shan/Desktop/img_processing/images5.jpg'\n",
    "predicted_name = predict_name_for_image(new_image_path, image_paths, names, loaded_siamese_model)\n",
    "print(f\"Predicted Name for the new image: {predicted_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf510fc1-4d4b-4389-80f7-f4f42ee3e47f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
